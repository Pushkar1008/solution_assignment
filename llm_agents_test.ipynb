{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbf1438c-d212-4713-8f3d-6def5da94fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import time\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "import json\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732299ba-4e25-4732-bed4-332b3e6b8c6a",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e2fa56-9ddb-4d87-8563-26e1a7230006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    id_match = re.search(r'<ID:(\\d+)>', text)\n",
    "    title_match = re.search(r'Title:\\s*(.+)', text)\n",
    "    abstract_match = re.search(r'Abstract:\\s*(.+)', text, re.DOTALL)\n",
    "\n",
    "    paper_id = id_match.group(1).strip() if id_match else None\n",
    "    title = title_match.group(1).strip() if title_match else None\n",
    "    abstract = abstract_match.group(1).strip().replace('\\n', ' ') if abstract_match else None\n",
    "\n",
    "    return paper_id, title, abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edb7530-41a8-40d0-9a2a-02cb397f3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(cancer_dir, non_cancer_dir, output_csv=\"cancer_dataset.csv\"):\n",
    "    data = []\n",
    "\n",
    "    for folder, label in [(cancer_dir, \"Cancer\"), (non_cancer_dir, \"Non-cancer\")]:\n",
    "        for file_name in os.listdir(folder):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                file_path = os.path.join(folder, file_name)\n",
    "                paper_id, title, abstract = extract_data_from_file(file_path)\n",
    "\n",
    "                if paper_id and title and abstract:\n",
    "                    data.append({\n",
    "                        \"id\": paper_id,\n",
    "                        \"title\": title,\n",
    "                        \"abstract\": abstract,\n",
    "                        \"class\": label\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"Skipped: {file_name} due to missing fields\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"CSV created: {output_csv} with {len(df)} records.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5922c3c-ec87-4b91-aba8-90aaf5b74cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_folder = \"Cancer/\"\n",
    "non_cancer_folder = \"Non-cancer\"\n",
    "output_csv_path = \"combined_articles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1dd293-e94c-4470-97fb-33bee6436158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created: combined_articles.csv with 1000 records.\n"
     ]
    }
   ],
   "source": [
    "data = build_dataset(cancer_folder, non_cancer_folder, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c421187a-59fe-484c-a629-8192fac66a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30872385</td>\n",
       "      <td>Comparison of methodologies for the detection ...</td>\n",
       "      <td>AIMS: BRAF V600E detection assists in the diag...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30873683</td>\n",
       "      <td>Tumour biomarkers-Tracing the molecular functi...</td>\n",
       "      <td>In recent years, with the increase in cancer m...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30874851</td>\n",
       "      <td>Pomalidomide, cyclophosphamide, and dexamethas...</td>\n",
       "      <td>Pomalidomide dexamethasone is a standard of ca...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30875581</td>\n",
       "      <td>Aggressive variants of prostate cancer - Are w...</td>\n",
       "      <td>Recently, adoption of novel drugs for systemic...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30875950</td>\n",
       "      <td>Circulating Tumour Cells (CTC), Head and Neck ...</td>\n",
       "      <td>Head and neck cancer is the seventh most commo...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>38623902</td>\n",
       "      <td>[Not Available].</td>\n",
       "      <td>Effective longitudinal biomarkers that track d...</td>\n",
       "      <td>Non-cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>38640937</td>\n",
       "      <td>Mechanisms and management of loss of response ...</td>\n",
       "      <td>We sought to report the effectiveness of infli...</td>\n",
       "      <td>Non-cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>38642556</td>\n",
       "      <td>Modification of coronary artery disease clinic...</td>\n",
       "      <td>The extent to which the relationships between ...</td>\n",
       "      <td>Non-cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>38650020</td>\n",
       "      <td>Meta-analysis of the global distribution of cl...</td>\n",
       "      <td>CYP2C8 is responsible for the metabolism of 5%...</td>\n",
       "      <td>Non-cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>38701783</td>\n",
       "      <td>FLT3L governs the development of partially ove...</td>\n",
       "      <td>FMS-related tyrosine kinase 3 ligand (FLT3L), ...</td>\n",
       "      <td>Non-cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0    30872385  Comparison of methodologies for the detection ...   \n",
       "1    30873683  Tumour biomarkers-Tracing the molecular functi...   \n",
       "2    30874851  Pomalidomide, cyclophosphamide, and dexamethas...   \n",
       "3    30875581  Aggressive variants of prostate cancer - Are w...   \n",
       "4    30875950  Circulating Tumour Cells (CTC), Head and Neck ...   \n",
       "..        ...                                                ...   \n",
       "995  38623902                                   [Not Available].   \n",
       "996  38640937  Mechanisms and management of loss of response ...   \n",
       "997  38642556  Modification of coronary artery disease clinic...   \n",
       "998  38650020  Meta-analysis of the global distribution of cl...   \n",
       "999  38701783  FLT3L governs the development of partially ove...   \n",
       "\n",
       "                                              abstract       class  \n",
       "0    AIMS: BRAF V600E detection assists in the diag...      Cancer  \n",
       "1    In recent years, with the increase in cancer m...      Cancer  \n",
       "2    Pomalidomide dexamethasone is a standard of ca...      Cancer  \n",
       "3    Recently, adoption of novel drugs for systemic...      Cancer  \n",
       "4    Head and neck cancer is the seventh most commo...      Cancer  \n",
       "..                                                 ...         ...  \n",
       "995  Effective longitudinal biomarkers that track d...  Non-cancer  \n",
       "996  We sought to report the effectiveness of infli...  Non-cancer  \n",
       "997  The extent to which the relationships between ...  Non-cancer  \n",
       "998  CYP2C8 is responsible for the metabolism of 5%...  Non-cancer  \n",
       "999  FMS-related tyrosine kinase 3 ligand (FLT3L), ...  Non-cancer  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe350f78-92a3-436d-9dcf-763d3186aa9f",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c3b4f4-cf1e-4a4f-a186-e715227b47b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\anaconda3\\envs\\llm_vm\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b86a832-33d9-4c89-94a3-b19b756d89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_articles.csv\")  # Update with your path\n",
    "df = df.rename(columns={\"class\": \"label\"})  # Ensure column is named 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68117fb4-480a-4ae3-852c-614aede9d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'].fillna('') + \"\\n\\n\" + df['abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68baa609-df01-4a52-92de-e3470c7fec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_cancer = df[df['label'] == 'Cancer'].sample(n=5, random_state=42)\n",
    "sampled_non_cancer = df[df['label'] == 'Non-cancer'].sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b446f94e-f650-4eb7-90a2-5c23e8af6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_sample = pd.concat([sampled_cancer, sampled_non_cancer]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea27742-2969-419f-8518-27269a055bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Non-cancer    5\n",
      "Cancer        5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(balanced_sample['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c842d6-c06d-4e46-ba37-735c3c854120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6517dc7e-3773-4344-9562-3acadb1a7b08",
   "metadata": {},
   "source": [
    "# LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350b7401-0ed4-4a77-8c4a-ba4408e94a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(text):\n",
    "\n",
    "    \"\"\"\n",
    "    Uses LLM to modify the associated chunk based on the instruction.\n",
    "    \"\"\"\n",
    "    n_ctx = 16384\n",
    "    llm = ChatOllama(model=\"llama3.1:8b-instruct-q8_0\", temperature=0.7, num_ctx=n_ctx)\n",
    "    \n",
    "    system_prompt = SystemMessage(content=\"\"\"\n",
    "    You are an expert in disease identification based on your training data. \n",
    "    Read given content and take action as per given query and apply all instructions given by user.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Strictly do not add any commentary, explanation, or additional words from your side.\n",
    "    \"\"\")\n",
    "    user_message=HumanMessage(content=f'''I have only two classes Cancer and Non-cancer, So for given text to you ,classify them in either of these 2 classes only, Make sure there is no variation of these 2 classes.\n",
    "        Text : {text}     \n",
    "        Answer : \n",
    "        ''')\n",
    "\n",
    "    response = llm([system_prompt, user_message])\n",
    "\n",
    "    # res_resp = restructure_llm(reference,ref_style)\n",
    "    result = response.content.strip()\n",
    "    # import ipdb;ipdb.set_trace()\n",
    "    # print(f\"LLm Response{result}\")\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e83ad85f-a1c0-4953-b94c-3b956d783977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_call_llm(texts, max_threads=10):\n",
    "    results = [None] * len(texts)\n",
    "\n",
    "    def task(index, text):\n",
    "        result = call_llm(text)\n",
    "        results[index] = result\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_threads) as executor:\n",
    "        futures = [executor.submit(task, i, text) for i, text in enumerate(texts)]\n",
    "        for _ in as_completed(futures):\n",
    "            pass  # we don't need to do anything here, just wait\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f5a65143-a0f6-4f7e-8728-2f5d41d459fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_handler(df, max_threads=10):\n",
    "    texts = df['text'].tolist()\n",
    "    df['predicted_label'] = parallel_call_llm(texts, max_threads=max_threads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "48f4937c-0d11-4488-b019-92d76eac6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prediction(label):\n",
    "    label = label.strip().lower()\n",
    "    if \"non-cancer\" in label:\n",
    "        return \"Non-cancer\"\n",
    "    elif \"cancer\" in label:\n",
    "        return \"Cancer\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e968c69-3345-47ea-92c1-b6eed81a0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas(desc=\"Classifying\")\n",
    "response_data = llm_handler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "16698675-58d6-46b0-b659-fbd5aeb581a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_prediction)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response_data' is not defined"
     ]
    }
   ],
   "source": [
    "response_data['predicted_label'] = response_data['predicted_label'].apply(normalize_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97dcc5a2-3986-468e-99e1-12bdfa25cccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_label\n",
       "Cancer        769\n",
       "Non-cancer    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ef30d-b8dc-4227-8444-1b45c50f318f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9f31c60-01df-4139-a92a-4c6978671f42",
   "metadata": {},
   "source": [
    "# Classification Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa7ef448-e0ac-4d45-839d-9cd67e145c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(data['label'], data['predicted_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "254bfd8f-3b1b-4ca1-998f-8f40594b1685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.61      0.94      0.74       500\n",
      "  Non-cancer       0.87      0.40      0.55       500\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.74      0.67      0.65      1000\n",
      "weighted avg       0.74      0.67      0.65      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a40b09-0d56-42bd-8b8e-350b579f5b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31c1154d-f2ea-433e-bd90-97886fbc1513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[471  29]\n",
      " [298 202]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(data['label'], data['predicted_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85bb4bb1-d79f-43b3-8cd6-11c62c3ed214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results saved as 'baseline_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "data.to_csv(\"baseline_predictions.csv\", index=False)\n",
    "print(\"\\n Results saved as 'baseline_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b55220-1565-4234-8317-80a1e2ed84c2",
   "metadata": {},
   "source": [
    "# Explaination\n",
    "### Why Llama\n",
    "\n",
    "#### 1. Choosing LLama as its decent in identification bit, I can reason and can maintain Chain of thought to figure out best result based on context         provide.\n",
    "#### 2. Low hallucinations makes it perfect for this task.\n",
    "\n",
    "### Use of Ollama and Langchain\n",
    "\n",
    "#### 1. Useing Ollama is absolute no-brainer for me as it can be hosted locally quite easily.\n",
    "\n",
    "#### 2. While Huggingface provides number of benifits, due to lack of time here, exploring those and hosting on spaces was not possible here.\n",
    "\n",
    "### Results Matrix\n",
    "\n",
    "#### 1. From results and with simplest prompt LLM was able to detect and resport back decent results with 67% overall accuracy.\n",
    "\n",
    "#### 2. This is done with assumption that Abstrct given and labels for them given in Problem Statement are in sync and thus are ground truth for me.\n",
    "\n",
    "### Self-Inputs\n",
    "\n",
    "#### 1. With little more time and some heurastical approach acuracy of LLM can be increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564fbb7-5160-4665-96ea-8243a889436b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838461c-e07b-4fbf-a233-b93cc8464145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff403901-752c-4f3a-8ea2-1fc7b34a0da9",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262e485-e3ef-42e7-8075-c4e82fe508bc",
   "metadata": {},
   "source": [
    "# Intial Thoughts\n",
    "#### 1. Doing fine tuning of any llm is time consuming and needs decent infra(GPU,memory), both not available with me\n",
    "\n",
    "#### 2. Choosing a sentence classifier might do more good than choosing llm fine tuning.(May be i am wrong here, but due to lack of time i am choosing Bert Model for fine tuning)\n",
    "\n",
    "#### 3. Bert base uncased model is really fast in fine tuning and inference is super quick. For desease identification task this will be perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "279c261f-f661-41e0-9276-c7d9eaf821cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2cf98699-0653-4301-a233-c49b813be377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_articles.csv\")  # Update with your path\n",
    "df['text'] = df['title'].fillna('') + \"\\n\\n\" + df['abstract'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "051f14ac-edfe-4247-ac7d-63f24d9557c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Cancer        500\n",
       "Non-cancer    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bff428d-631c-49b7-933f-590ffd90892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\AppData\\Local\\Temp\\ipykernel_16520\\3448654713.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['class'] = df['class'].replace({\n"
     ]
    }
   ],
   "source": [
    "df['class'] = df['class'].replace({\n",
    "    'Cancer': 1,\n",
    "    'Non-cancer': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46935c29-f536-4afe-b417-659e6e1101d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['class'].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "144a6687-8c76-4e53-91b0-850e83953f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['class'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d86306fe-b2bf-4ca2-9b98-fe3665099c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={'class': 'labels'})\n",
    "test_df = test_df.rename(columns={'class': 'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b9c90ef-9681-4320-91d1-9b01b1b40bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d9ff5c8-33fc-470d-b07d-6d90e3acf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding=\"max_length\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d90baff4-4923-4efc-a9d5-0992de93be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cb74c40-991b-42fa-a859-b16ced3b2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [00:02<00:00, 305.29 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:00<00:00, 309.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "}).map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44a212d0-4445-43c6-a498-ae240f6fe294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['text', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aee0e89a-d977-403c-84a4-dd73f48694e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbfdff4f-9a5d-4b4b-8102-45b55652cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8aeb38b5-e1ab-4224-ada8-272791bf15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision_cancer': report['1']['precision'],\n",
    "        'recall_cancer': report['1']['recall'],\n",
    "        'f1_cancer': report['1']['f1-score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bfa93697-bd58-4138-8e81-d78a5b7a7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7f2a77a-d4da-4400-9d12-16920169d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a1fdd12a-1e2a-4a4e-bb55-f9c0878c5cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 00:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Cancer</th>\n",
       "      <th>Recall Cancer</th>\n",
       "      <th>F1 Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.201244</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.938776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.162605</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.972028</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.948805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142985</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.966443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=132, training_loss=0.2220440199880889, metrics={'train_runtime': 37.8345, 'train_samples_per_second': 55.505, 'train_steps_per_second': 3.489, 'total_flos': 138133304064000.0, 'train_loss': 0.2220440199880889, 'epoch': 3.0})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6765896e-adfb-4645-bc62-106ac6cb6d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset['test'])\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7425feea-2204-4538-8641-ba258195f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       150\n",
      "           1       0.97      0.96      0.97       150\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.97      0.97      0.97       300\n",
      "weighted avg       0.97      0.97      0.97       300\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[146   4]\n",
      " [  6 144]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405ae6b-4661-430a-9e30-1756cb50a280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6790ef0-aae8-4cad-a3c5-1a23c6bb971a",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1115005-efce-437a-aa7a-d0ac87f3c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"bert-cancer-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d4cbccae-9380-4a1e-a9c9-c31592d976c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bert-cancer-classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc0d6f1-1506-4492-9233-117dba22991c",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3605d759-b77d-48dc-a4ad-41dd9d1c3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18ba6e2a-0b11-4f47-ae33-996ba3d34892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b3f24c9-cebc-4901-9272-7bf21cc93a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9974588751792908}]\n"
     ]
    }
   ],
   "source": [
    "# classifier = pipeline(\"text-classification\", model=\"bert-cancer-classifier\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d326d-5ff1-49ce-8f5d-f3de6e077585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "792f4fb9-c544-48ed-a4a3-1a3f832e9bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "561903ed-06ad-4ced-9947-8be5198e6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\anaconda3\\envs\\llm_vm\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5f2945d3-0335-4c12-9f77-2b41643fe3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushk\\AppData\\Local\\Temp\\ipykernel_16520\\2114578673.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"bert-cancer-classifier.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"bert-cancer-classifier.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8fb68025-329e-464b-b7d0-fdcd389e0716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2767018-c204-44ff-817a-3faf81a2342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, tokenizer, model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize and move inputs to the same device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return \"Cancer\" if predicted_class == 1 else \"Non-cancer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42b3812f-e502-46aa-9112-e07a18f799d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Pathogenic heterozygous mutations in the progranulin gene (GRN) are a key cause of frontotemporal dementia (FTD), leading to significantly reduced biofluid concentrations of the progranulin protein (PGRN). This has led to a number of ongoing therapeutic trials aiming to treat this form of FTD by increasing PGRN levels in mutation carriers. However, we currently lack a complete understanding of factors that affect PGRN levels and potential variation in measurement methods. Here, we aimed to address this gap in knowledge by systematically reviewing published literature on biofluid PGRN concentrations. Published data including biofluid PGRN concentration, age, sex, diagnosis and GRN mutation were collected for 7071 individuals from 75 publications. The majority of analyses (72%) had focused on plasma PGRN concentrations, with many of these (56%) measured with a single assay type (Adipogen) and so the influence of mutation type, age at onset, sex, and diagnosis were investigated in this subset of the data. We established a plasma PGRN concentration cut-off between pathogenic mutation carriers and non-carriers of 74.8Ã‚Â ng/mL using the Adipogen assay based on 3301 individuals, with a CSF concentration cut-off of 3.43Ã‚Â ng/mL. Plasma PGRN concentration varied by GRN mutation type as well as by clinical diagnosis in those without a GRN mutation. Plasma PGRN concentration was significantly higher in women than men in GRN mutation carriers (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.007) with a trend in non-carriers (pÃ¢â‚¬â€°=Ã¢â‚¬â€°0.062), and there was a significant but weak positive correlation with age in both GRN mutation carriers and non-carriers. No significant association was seen with weight or with TMEM106B rs1990622 genotype. However, higher plasma PGRN levels were seen in those with the GRN rs5848 CC genotype in both GRN mutation carriers and non-carriers. These results further support the usefulness of PGRN concentration for the identification of the large majority of pathogenic mutations in the GRN gene. Furthermore, these results highlight the importance of considering additional factors, such as mutation type, sex and age when interpreting PGRN concentrations. This will be particularly important as we enter the era of trials for progranulin-associated FTD.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f8532f77-01be-47aa-8457-f3ff76ee01e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cancer\n"
     ]
    }
   ],
   "source": [
    "print(predict(text, tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a224c0-8c04-473e-b88e-fb44511ec12c",
   "metadata": {},
   "source": [
    "# Final Explainations\n",
    "\n",
    "#### 1. I have treained on 70% dataset and kept 30% for creaying inferences.\n",
    "\n",
    "#### 2. Looking into classification of Cancer vs Non-cancer, model aced it with 97% accuracy on limited 300 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912372d-bbf5-4721-a8d1-86da0743a985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
